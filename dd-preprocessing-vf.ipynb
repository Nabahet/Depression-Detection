{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52b59dc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-21T08:17:40.128864Z",
     "iopub.status.busy": "2025-05-21T08:17:40.128537Z",
     "iopub.status.idle": "2025-05-21T08:17:42.123569Z",
     "shell.execute_reply": "2025-05-21T08:17:42.122626Z"
    },
    "papermill": {
     "duration": 2.001324,
     "end_time": "2025-05-21T08:17:42.125213",
     "exception": false,
     "start_time": "2025-05-21T08:17:40.123889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_standardize_split(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'PHQ_Binary' in df.columns:\n",
    "        df = df.rename(columns={'PHQ_Binary': 'PHQ8_Binary'})\n",
    "    return df\n",
    "\n",
    "# Charger les splits\n",
    "train_df = load_and_standardize_split(\"/kaggle/input/daic-wozz/train_split_Depression_AVEC2017.csv\")\n",
    "dev_df = load_and_standardize_split(\"/kaggle/input/daic-wozz/dev_split_Depression_AVEC2017.csv\")\n",
    "test_df = load_and_standardize_split(\"/kaggle/input/daic-wozz/full_test_split.csv\")\n",
    "\n",
    "# Fusion\n",
    "full_df = pd.concat([train_df, dev_df, test_df], ignore_index=True)\n",
    "full_df['Participant_ID'] = full_df['Participant_ID'].astype(int)\n",
    "\n",
    "# Générer les chemins et créer la liste des données\n",
    "base_path = \"/kaggle/input/daic-wozz\"\n",
    "data = []\n",
    "\n",
    "for _, row in full_df.iterrows():\n",
    "    pid = row[\"Participant_ID\"]\n",
    "    pid_int = int(float(pid))  # convertit 303.0 en 303\n",
    "    \n",
    "    folder_name = f\"{pid_int}_P\"\n",
    "    audio_path = os.path.join(base_path, folder_name, f\"{pid_int}_AUDIO.wav\")\n",
    "    transcript_path = os.path.join(base_path, folder_name, f\"{pid_int}_TRANSCRIPT.csv\")\n",
    "    \n",
    "    data.append({\n",
    "        \"Participant_ID\": pid_int,\n",
    "        \"audio_path\": audio_path,\n",
    "        \"transcript_path\": transcript_path,\n",
    "        \"PHQ8_Binary\": int(row[\"PHQ8_Binary\"])\n",
    "    })\n",
    "\n",
    "# Créer le DataFrame final\n",
    "daic_paths_df = pd.DataFrame(data)\n",
    "daic_paths_df['Participant_ID'] = daic_paths_df['Participant_ID'].astype(int)\n",
    "\n",
    "# Sauvegarder\n",
    "daic_paths_df.to_csv(\"daic_paths.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0827330e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:17:42.133210Z",
     "iopub.status.busy": "2025-05-21T08:17:42.132049Z",
     "iopub.status.idle": "2025-05-21T08:17:42.144730Z",
     "shell.execute_reply": "2025-05-21T08:17:42.143644Z"
    },
    "papermill": {
     "duration": 0.017668,
     "end_time": "2025-05-21T08:17:42.146161",
     "exception": false,
     "start_time": "2025-05-21T08:17:42.128493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Participant_ID                                   audio_path  \\\n",
      "0               303  /kaggle/input/daic-wozz/303_P/303_AUDIO.wav   \n",
      "1               304  /kaggle/input/daic-wozz/304_P/304_AUDIO.wav   \n",
      "2               305  /kaggle/input/daic-wozz/305_P/305_AUDIO.wav   \n",
      "3               310  /kaggle/input/daic-wozz/310_P/310_AUDIO.wav   \n",
      "4               312  /kaggle/input/daic-wozz/312_P/312_AUDIO.wav   \n",
      "..              ...                                          ...   \n",
      "184             467  /kaggle/input/daic-wozz/467_P/467_AUDIO.wav   \n",
      "185             469  /kaggle/input/daic-wozz/469_P/469_AUDIO.wav   \n",
      "186             470  /kaggle/input/daic-wozz/470_P/470_AUDIO.wav   \n",
      "187             480  /kaggle/input/daic-wozz/480_P/480_AUDIO.wav   \n",
      "188             481  /kaggle/input/daic-wozz/481_P/481_AUDIO.wav   \n",
      "\n",
      "                                      transcript_path  PHQ8_Binary  \n",
      "0    /kaggle/input/daic-wozz/303_P/303_TRANSCRIPT.csv            0  \n",
      "1    /kaggle/input/daic-wozz/304_P/304_TRANSCRIPT.csv            0  \n",
      "2    /kaggle/input/daic-wozz/305_P/305_TRANSCRIPT.csv            0  \n",
      "3    /kaggle/input/daic-wozz/310_P/310_TRANSCRIPT.csv            0  \n",
      "4    /kaggle/input/daic-wozz/312_P/312_TRANSCRIPT.csv            0  \n",
      "..                                                ...          ...  \n",
      "184  /kaggle/input/daic-wozz/467_P/467_TRANSCRIPT.csv            0  \n",
      "185  /kaggle/input/daic-wozz/469_P/469_TRANSCRIPT.csv            0  \n",
      "186  /kaggle/input/daic-wozz/470_P/470_TRANSCRIPT.csv            0  \n",
      "187  /kaggle/input/daic-wozz/480_P/480_TRANSCRIPT.csv            0  \n",
      "188  /kaggle/input/daic-wozz/481_P/481_TRANSCRIPT.csv            0  \n",
      "\n",
      "[189 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(daic_paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578ab853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:17:42.153169Z",
     "iopub.status.busy": "2025-05-21T08:17:42.152655Z",
     "iopub.status.idle": "2025-05-21T08:17:44.720199Z",
     "shell.execute_reply": "2025-05-21T08:17:44.719176Z"
    },
    "papermill": {
     "duration": 2.572634,
     "end_time": "2025-05-21T08:17:44.721714",
     "exception": false,
     "start_time": "2025-05-21T08:17:42.149080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# === LOAD GLOVE EMBEDDINGS ===\n",
    "def load_glove_model(file_path):\n",
    "    model = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            split_line = line.strip().split()\n",
    "            word = split_line[0]\n",
    "            vector = np.asarray(split_line[1:], dtype='float32')\n",
    "            model[word] = vector\n",
    "    return model\n",
    "\n",
    "# === AUDIO FUNCTIONS ===\n",
    "def get_patient_timestamps(transcript_path):\n",
    "    df = pd.read_csv(transcript_path, sep=\"\\t\")\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df[df['speaker'].str.lower() == 'participant']\n",
    "    return list(df[['start_time', 'stop_time']].itertuples(index=False, name=None))\n",
    "\n",
    "def load_patient_audio(audio_path, timestamps):\n",
    "    y, sr = librosa.load(audio_path, sr=16000)\n",
    "    patient_audio = [y[int(start * sr):int(end * sr)] for start, end in timestamps]\n",
    "    return np.concatenate(patient_audio), sr\n",
    "\n",
    "def segment_audio(audio, sr, segment_duration=7.6):\n",
    "    segment_samples = int(segment_duration * sr)\n",
    "    segments = [audio[i:i+segment_samples] for i in range(0, len(audio), segment_samples)]\n",
    "    if len(segments[-1]) < segment_samples:\n",
    "        segments = segments[:-1]\n",
    "    return segments\n",
    "\n",
    "def augment_audio(segments, noise_factor=0.005):\n",
    "    return [seg + noise_factor * np.random.randn(len(seg)) for seg in segments]\n",
    "\n",
    "def extract_mfcc_audio(segments, sr, n_mfcc=60, n_fft=1024, hop_length=322, win_length=960):\n",
    "    return [librosa.feature.mfcc(y=seg, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft,\n",
    "                                 hop_length=hop_length, win_length=win_length).T for seg in segments]\n",
    "\n",
    "# === TEXT FUNCTIONS ===\n",
    "def segment_transcripts(transcript_path, segment_duration=7.6):\n",
    "    df = pd.read_csv(transcript_path, sep='\\t')\n",
    "    df = df.dropna(subset=['value'])\n",
    "    total_time = df['stop_time'].max()\n",
    "    n_segments = int(np.ceil(total_time / segment_duration))\n",
    "    segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start, end = i * segment_duration, (i + 1) * segment_duration\n",
    "        segment = df[(df['start_time'] >= start) & (df['stop_time'] < end)]\n",
    "        text = \" \".join(segment['value'].astype(str).tolist())\n",
    "        segments.append(text)\n",
    "\n",
    "    return segments\n",
    "\n",
    "def text_to_embedding(text, model, max_words=9, emb_size=100):\n",
    "    words = text.split()\n",
    "    vecs = [model.get(w.lower(), np.zeros(emb_size)) for w in words[:max_words]]\n",
    "    while len(vecs) < max_words:\n",
    "        vecs.append(np.zeros(emb_size))\n",
    "    emb = np.stack(vecs, axis=0).T  # shape (100, 9)\n",
    "    if emb.shape[0] < 378:\n",
    "        pad = np.zeros((378 - emb.shape[0], emb.shape[1]))\n",
    "        emb = np.vstack((emb, pad))\n",
    "    return emb  # shape (378, 9)\n",
    "\n",
    "# === TRAITEMENT PAR PATIENT ===\n",
    "def process_patient(audio_path, transcript_path, glove_model):\n",
    "    try:\n",
    "        timestamps = get_patient_timestamps(transcript_path)\n",
    "        patient_audio, sr = load_patient_audio(audio_path, timestamps)\n",
    "        audio_segments = segment_audio(patient_audio, sr)\n",
    "        audio_segments = augment_audio(audio_segments)\n",
    "        mfcc_audio = extract_mfcc_audio(audio_segments, sr)\n",
    "\n",
    "        text_segments = segment_transcripts(transcript_path)\n",
    "        mfcc_text = [text_to_embedding(t, glove_model) for t in text_segments]\n",
    "\n",
    "        n_segments = min(len(mfcc_audio), len(mfcc_text))\n",
    "        return mfcc_audio[:n_segments], mfcc_text[:n_segments]\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur patient {audio_path} : {e}\")\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37fc17d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:17:44.729354Z",
     "iopub.status.busy": "2025-05-21T08:17:44.728838Z",
     "iopub.status.idle": "2025-05-21T08:17:44.735997Z",
     "shell.execute_reply": "2025-05-21T08:17:44.735234Z"
    },
    "papermill": {
     "duration": 0.012633,
     "end_time": "2025-05-21T08:17:44.737338",
     "exception": false,
     "start_time": "2025-05-21T08:17:44.724705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === PIPELINE PRINCIPAL ===\n",
    "def build_dataset(csv_path, glove_path, output_path=\"processed_daic_dataset.npz\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    glove_model = load_glove_model(glove_path)\n",
    "\n",
    "    all_audio = []\n",
    "    all_text = []\n",
    "    all_labels = []\n",
    "    all_ids = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        audio_path = row[\"audio_path\"]\n",
    "        transcript_path = row[\"transcript_path\"]\n",
    "        label = row[\"PHQ8_Binary\"]\n",
    "        patient_id = row[\"Participant_ID\"]\n",
    "\n",
    "        mfcc_audio, mfcc_text = process_patient(audio_path, transcript_path, glove_model)\n",
    "\n",
    "        for a, t in zip(mfcc_audio, mfcc_text):\n",
    "            all_audio.append(a)\n",
    "            all_text.append(t)\n",
    "            all_labels.append(label)\n",
    "            all_ids.append(patient_id)\n",
    "\n",
    "    np.savez_compressed(output_path,\n",
    "                        ids=np.array(all_ids),\n",
    "                        X_audio=np.array(all_audio, dtype=object),\n",
    "                        X_text=np.array(all_text, dtype=object),\n",
    "                        y=np.array(all_labels))\n",
    "    \n",
    "    print(f\"✅ Dataset sauvegardé : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189adc84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:17:44.744619Z",
     "iopub.status.busy": "2025-05-21T08:17:44.744271Z",
     "iopub.status.idle": "2025-05-21T08:27:35.728750Z",
     "shell.execute_reply": "2025-05-21T08:27:35.727254Z"
    },
    "papermill": {
     "duration": 591.000894,
     "end_time": "2025-05-21T08:27:35.741406",
     "exception": false,
     "start_time": "2025-05-21T08:17:44.740512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [05:18<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset sauvegardé : processed_dataset.npz\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/kaggle/working/daic_paths.csv\"\n",
    "glove_path = \"/kaggle/input/glove-model/glove.6B.100d.txt\"  # or any other dimension you used\n",
    "output_path = \"processed_dataset.npz\"  # optional\n",
    "\n",
    "build_dataset(csv_path, glove_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a0c493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:27:35.766944Z",
     "iopub.status.busy": "2025-05-21T08:27:35.766531Z",
     "iopub.status.idle": "2025-05-21T08:28:47.688848Z",
     "shell.execute_reply": "2025-05-21T08:28:47.687217Z"
    },
    "papermill": {
     "duration": 71.938954,
     "end_time": "2025-05-21T08:28:47.692054",
     "exception": false,
     "start_time": "2025-05-21T08:27:35.753100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.load(\"/kaggle/working/processed_dataset.npz\", allow_pickle=True)\n",
    "X_audio = data[\"X_audio\"]\n",
    "X_text = data[\"X_text\"]\n",
    "y = data[\"y\"]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d35cadd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:28:47.718887Z",
     "iopub.status.busy": "2025-05-21T08:28:47.718144Z",
     "iopub.status.idle": "2025-05-21T08:28:53.567833Z",
     "shell.execute_reply": "2025-05-21T08:28:53.567105Z"
    },
    "papermill": {
     "duration": 5.864196,
     "end_time": "2025-05-21T08:28:53.569457",
     "exception": false,
     "start_time": "2025-05-21T08:28:47.705261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Split train (80%) et temp (20%)\n",
    "X_audio_train, X_audio_temp, X_text_train, X_text_temp, y_train, y_temp = train_test_split(\n",
    "    X_audio, X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2) Split temp (20%) en dev (10%) et test (10%)\n",
    "X_audio_dev, X_audio_test, X_text_dev, X_text_test, y_dev, y_test = train_test_split(\n",
    "    X_audio_temp, X_text_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792f0a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:28:53.595952Z",
     "iopub.status.busy": "2025-05-21T08:28:53.595426Z",
     "iopub.status.idle": "2025-05-21T08:28:53.602820Z",
     "shell.execute_reply": "2025-05-21T08:28:53.602005Z"
    },
    "papermill": {
     "duration": 0.021484,
     "end_time": "2025-05-21T08:28:53.604359",
     "exception": false,
     "start_time": "2025-05-21T08:28:53.582875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "object\n",
      "(9187, 378, 60)\n",
      "<class 'numpy.ndarray'>\n",
      "(378, 60)\n",
      "<class 'numpy.ndarray'>\n",
      "object\n",
      "(9187, 378, 9)\n",
      "<class 'numpy.ndarray'>\n",
      "(378, 9)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_audio_train))\n",
    "print(X_audio_train.dtype)\n",
    "print(X_audio_train.shape)\n",
    "print(type(X_audio_train[0]))\n",
    "print(np.array(X_audio_train[0]).shape)\n",
    "\n",
    "print(type(X_text_train))\n",
    "print(X_text_train.dtype)\n",
    "print(X_text_train.shape)\n",
    "print(type(X_text_train[0]))\n",
    "print(np.array(X_text_train[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aae6011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:28:53.629888Z",
     "iopub.status.busy": "2025-05-21T08:28:53.629018Z",
     "iopub.status.idle": "2025-05-21T08:29:43.209284Z",
     "shell.execute_reply": "2025-05-21T08:29:43.208470Z"
    },
    "papermill": {
     "duration": 49.594313,
     "end_time": "2025-05-21T08:29:43.211000",
     "exception": false,
     "start_time": "2025-05-21T08:28:53.616687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_audio_train = np.array(X_audio_train.tolist(), dtype=np.float32)\n",
    "X_text_train = np.array(X_text_train.tolist(), dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "\n",
    "X_audio_dev = np.array(X_audio_dev.tolist(), dtype=np.float32)\n",
    "X_text_dev = np.array(X_text_dev.tolist(), dtype=np.float32)\n",
    "y_dev = np.array(y_dev, dtype=np.float32)\n",
    "\n",
    "X_audio_test = np.array(X_audio_test.tolist(), dtype=np.float32)\n",
    "X_text_test = np.array(X_text_test.tolist(), dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8b62da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:29:43.235548Z",
     "iopub.status.busy": "2025-05-21T08:29:43.235258Z",
     "iopub.status.idle": "2025-05-21T08:30:42.944383Z",
     "shell.execute_reply": "2025-05-21T08:30:42.943473Z"
    },
    "papermill": {
     "duration": 59.723134,
     "end_time": "2025-05-21T08:30:42.946166",
     "exception": false,
     "start_time": "2025-05-21T08:29:43.223032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    '/kaggle/working/dataset.npz',\n",
    "    X_audio_train=X_audio_train,\n",
    "    X_text_train=X_text_train,\n",
    "    y_train=y_train,\n",
    "    X_audio_dev=X_audio_dev,\n",
    "    X_text_dev=X_text_dev,\n",
    "    y_dev=y_dev,\n",
    "    X_audio_test=X_audio_test,\n",
    "    X_text_test=X_text_test,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc9a12",
   "metadata": {
    "papermill": {
     "duration": 0.010835,
     "end_time": "2025-05-21T08:30:42.968793",
     "exception": false,
     "start_time": "2025-05-21T08:30:42.957958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7387964,
     "sourceId": 11768119,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7471404,
     "sourceId": 11887204,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 790.793039,
   "end_time": "2025-05-21T08:30:46.205937",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-21T08:17:35.412898",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
