{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11699724,"sourceType":"datasetVersion","datasetId":7343598}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install language-tool-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:01:26.417734Z","iopub.execute_input":"2025-05-08T10:01:26.417974Z","iopub.status.idle":"2025-05-08T10:01:30.784145Z","shell.execute_reply.started":"2025-05-08T10:01:26.417950Z","shell.execute_reply":"2025-05-08T10:01:30.783257Z"}},"outputs":[{"name":"stdout","text":"Collecting language-tool-python\n  Downloading language_tool_python-2.9.3-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (7.0.0)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.1.31)\nDownloading language_tool_python-2.9.3-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: language-tool-python\nSuccessfully installed language-tool-python-2.9.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nimport os\nimport re\nimport nltk\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport language_tool_python\nfrom gensim.models.fasttext import load_facebook_vectors\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:01:30.786285Z","iopub.execute_input":"2025-05-08T10:01:30.786558Z","iopub.status.idle":"2025-05-08T10:02:05.183006Z","shell.execute_reply.started":"2025-05-08T10:01:30.786537Z","shell.execute_reply":"2025-05-08T10:02:05.182438Z"}},"outputs":[{"name":"stderr","text":"2025-05-08 10:01:54.638849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746698514.855954      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746698514.916955      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def load_audio(audio_path, sr=16000):\n    return librosa.load(audio_path, sr=sr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.183700Z","iopub.execute_input":"2025-05-08T10:02:05.184277Z","iopub.status.idle":"2025-05-08T10:02:05.188330Z","shell.execute_reply.started":"2025-05-08T10:02:05.184251Z","shell.execute_reply":"2025-05-08T10:02:05.187606Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def slice_patient_audio(y, sr, timestamps, segment_length=7.6):\n    \"\"\"Keep only patient’s speech using provided timestamps and split into 7.6s segments\"\"\"\n    patient_audio = np.concatenate([y[int(start*sr):int(end*sr)] for start, end in timestamps])\n    segments = []\n    segment_samples = int(segment_length * sr)\n    for i in range(0, len(patient_audio), segment_samples):\n        chunk = patient_audio[i:i + segment_samples]\n        if len(chunk) == segment_samples:\n            segments.append(chunk)\n    return segments\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.189099Z","iopub.execute_input":"2025-05-08T10:02:05.189613Z","iopub.status.idle":"2025-05-08T10:02:05.266145Z","shell.execute_reply.started":"2025-05-08T10:02:05.189588Z","shell.execute_reply":"2025-05-08T10:02:05.265382Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def add_noise(y, noise_factor):\n    return y + noise_factor * np.random.randn(len(y))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.267001Z","iopub.execute_input":"2025-05-08T10:02:05.267226Z","iopub.status.idle":"2025-05-08T10:02:05.277692Z","shell.execute_reply.started":"2025-05-08T10:02:05.267201Z","shell.execute_reply":"2025-05-08T10:02:05.277001Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def pitch_shift(y, sr, steps):\n    return librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.278465Z","iopub.execute_input":"2025-05-08T10:02:05.278737Z","iopub.status.idle":"2025-05-08T10:02:05.289663Z","shell.execute_reply.started":"2025-05-08T10:02:05.278703Z","shell.execute_reply":"2025-05-08T10:02:05.288959Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def extract_mfcc(y, sr=16000, n_mfcc=19, win_length=0.06):\n    hop_length = int(sr * win_length / 2)\n    win_len = int(sr * win_length)\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, \n                                hop_length=hop_length, win_length=win_len,\n                                window='hamming')\n    return mfcc.T  # shape (frames, n_mfcc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.292081Z","iopub.execute_input":"2025-05-08T10:02:05.292297Z","iopub.status.idle":"2025-05-08T10:02:05.300616Z","shell.execute_reply.started":"2025-05-08T10:02:05.292282Z","shell.execute_reply":"2025-05-08T10:02:05.299888Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# -------- CNN MODEL --------\n\nclass AudioCNNEncoder(nn.Module):\n    def __init__(self, input_shape):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1)\n        self.dropout = nn.Dropout(0.3)\n        self.flatten = nn.Flatten()\n        self.fc = nn.Linear(32 * input_shape[0] * input_shape[1], 128)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.flatten(x)\n        return self.fc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.301407Z","iopub.execute_input":"2025-05-08T10:02:05.301859Z","iopub.status.idle":"2025-05-08T10:02:05.314004Z","shell.execute_reply.started":"2025-05-08T10:02:05.301819Z","shell.execute_reply":"2025-05-08T10:02:05.313260Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def process_all_patients(dataset_dir, patient_timestamps_dict, cnn_model, sr=16000, segment_len=7.6, device='cpu'):\n    cnn_model.to(device)\n    cnn_model.eval()\n\n    processed_data = {}\n\n    for patient_prefix in tqdm(patient_timestamps_dict):\n        audio_path = os.path.join(dataset_dir, f\"{patient_prefix}.wav\")\n        if not os.path.exists(audio_path): continue\n\n        y, _ = load_audio(audio_path, sr)\n        segments = slice_patient_audio(y, sr, patient_timestamps_dict[patient_prefix], segment_len)\n\n        embeddings = []\n\n        for seg in segments:\n            augmented_versions = [seg]\n            # Noise Injection\n            for alpha in [0.01, 0.02, 0.03]:\n                augmented_versions.append(add_noise(seg, alpha))\n            # Pitch Shifting\n            for steps in [-0.5, -2, -2.5]:\n                augmented_versions.append(pitch_shift(seg, sr, steps))\n\n            for aug in augmented_versions:\n                mfcc = extract_mfcc(aug, sr)  # shape: (frames, 19)\n                mfcc_tensor = torch.tensor(mfcc).unsqueeze(0).unsqueeze(0).float().to(device)  # (1, 1, frames, 19)\n                with torch.no_grad():\n                    embedding = cnn_model(mfcc_tensor)\n                embeddings.append(embedding.cpu().numpy())\n\n        # Average all embeddings for the patient\n        processed_data[patient_prefix] = np.mean(embeddings, axis=0)\n\n    return processed_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.314650Z","iopub.execute_input":"2025-05-08T10:02:05.314831Z","iopub.status.idle":"2025-05-08T10:02:05.327563Z","shell.execute_reply.started":"2025-05-08T10:02:05.314818Z","shell.execute_reply":"2025-05-08T10:02:05.326868Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Télécharger les ressources nécessaires NLTK\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n\n# Initialisation\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.328326Z","iopub.execute_input":"2025-05-08T10:02:05.328557Z","iopub.status.idle":"2025-05-08T10:02:05.659824Z","shell.execute_reply.started":"2025-05-08T10:02:05.328541Z","shell.execute_reply":"2025-05-08T10:02:05.659272Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"window_size = 7.6\nwindows = []\ncurrent = 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.660649Z","iopub.execute_input":"2025-05-08T10:02:05.660920Z","iopub.status.idle":"2025-05-08T10:02:05.664662Z","shell.execute_reply.started":"2025-05-08T10:02:05.660895Z","shell.execute_reply":"2025-05-08T10:02:05.663995Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Chemin vers le dossier des données\nbase_dir = '/kaggle/input/daic-woz'\nall_vectors = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.665397Z","iopub.execute_input":"2025-05-08T10:02:05.665696Z","iopub.status.idle":"2025-05-08T10:02:05.677638Z","shell.execute_reply.started":"2025-05-08T10:02:05.665676Z","shell.execute_reply":"2025-05-08T10:02:05.677144Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"pip install compress-fasttext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:05.678290Z","iopub.execute_input":"2025-05-08T10:02:05.678750Z","iopub.status.idle":"2025-05-08T10:02:16.557174Z","shell.execute_reply.started":"2025-05-08T10:02:05.678728Z","shell.execute_reply":"2025-05-08T10:02:16.556355Z"}},"outputs":[{"name":"stdout","text":"Collecting compress-fasttext\n  Downloading compress-fasttext-0.1.5.tar.gz (15 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from compress-fasttext) (4.3.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from compress-fasttext) (1.26.4)\nCollecting scipy<1.14.0,>=1.7.0 (from gensim>=4.0.0->compress-fasttext)\n  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.0.0->compress-fasttext) (7.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->compress-fasttext) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->compress-fasttext) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->compress-fasttext) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->compress-fasttext) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->compress-fasttext) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->compress-fasttext) (2.4.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim>=4.0.0->compress-fasttext) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->compress-fasttext) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->compress-fasttext) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->compress-fasttext) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->compress-fasttext) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->compress-fasttext) (2024.2.0)\nDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: compress-fasttext\n  Building wheel for compress-fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for compress-fasttext: filename=compress_fasttext-0.1.5-py3-none-any.whl size=16097 sha256=308f1a11d88e9142d3552bf226688e4bf6158fb8fe9b1dec734fd550e6be3cbb\n  Stored in directory: /root/.cache/pip/wheels/90/ed/77/0a7fc5e08ff30e062f09c6904844a5911a9e30a7e5ec376890\nSuccessfully built compress-fasttext\nInstalling collected packages: scipy, compress-fasttext\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.2\n    Uninstalling scipy-1.15.2:\n      Successfully uninstalled scipy-1.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed compress-fasttext-0.1.5 scipy-1.13.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import gensim.downloader as api\n\n# Load the GloVe model (100-dimensional, small size)\nglove_model = api.load(\"glove-wiki-gigaword-100\")  # Only ~130MB, works fine on Kaggle\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:16.558144Z","iopub.execute_input":"2025-05-08T10:02:16.558394Z","iopub.status.idle":"2025-05-08T10:02:54.507269Z","shell.execute_reply.started":"2025-05-08T10:02:16.558369Z","shell.execute_reply":"2025-05-08T10:02:54.506686Z"}},"outputs":[{"name":"stdout","text":"[======================================------------] 76.6% 98.1/128.1MB downloaded","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=10000.0 (msgs/sec)\nNotebookApp.rate_limit_window=1.0 (secs)\n\n","name":"stderr","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"while current < data['stop'].max():\n    win_data = data[(data['start'] < current + window_size) & (data['stop'] > current)]\n    participant_text = \" \".join(win_data[win_data['speaker'] == 'Participant']['text'])\n    interviewer_text = \" \".join(win_data[win_data['speaker'] == 'Interviewer']['text'])\n    windows.append({\n        'start': current,\n        'end': current + window_size,\n        'participant_text': participant_text,\n        'interviewer_text': interviewer_text\n    })\n    current += window_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:54.508024Z","iopub.execute_input":"2025-05-08T10:02:54.508285Z","iopub.status.idle":"2025-05-08T10:02:54.809189Z","shell.execute_reply.started":"2025-05-08T10:02:54.508263Z","shell.execute_reply":"2025-05-08T10:02:54.808238Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3373466150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mwin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparticipant_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Participant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minterviewer_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Interviewer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     windows.append({\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"],"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3373466150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mwin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparticipant_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Participant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minterviewer_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwin_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Interviewer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     windows.append({\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"],"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"model = load_facebook_vectors('cc.en.300.bin')  # change le chemin si besoin\n\ndef text_to_matrix(text, max_words=9):\n    tokens = preprocess_text(text)\n    tokens = tokens[:max_words] + ['<pad>'] * (max_words - len(tokens))\n    matrix = []\n    for token in tokens:\n        if token in model:\n            matrix.append(model[token])\n        else:\n            matrix.append(np.zeros(300))  # vecteur nul pour les mots inconnus\n    return np.array(matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:54.809696Z","iopub.status.idle":"2025-05-08T10:02:54.809995Z","shell.execute_reply.started":"2025-05-08T10:02:54.809815Z","shell.execute_reply":"2025-05-08T10:02:54.809829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def resize_matrix_to_target(embedding_matrix, target_shape=(378, 9)):\n    current_shape = embedding_matrix.shape\n    resized = np.zeros(target_shape)\n    min_rows = min(target_shape[0], current_shape[0])\n    min_cols = min(target_shape[1], current_shape[1])\n    resized[:min_rows, :min_cols] = embedding_matrix[:min_rows, :min_cols]\n    return resized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:54.811102Z","iopub.status.idle":"2025-05-08T10:02:54.811395Z","shell.execute_reply.started":"2025-05-08T10:02:54.811273Z","shell.execute_reply":"2025-05-08T10:02:54.811287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 5. Construction des matrices (une par segment) ===\ntext_matrices = []\nfor win in windows:\n    combined_text = win['participant_text'] + \" \" + win['interviewer_text']\n    mat = text_to_matrix(combined_text)\n    text_matrices.append(mat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:54.812861Z","iopub.status.idle":"2025-05-08T10:02:54.813110Z","shell.execute_reply.started":"2025-05-08T10:02:54.813003Z","shell.execute_reply":"2025-05-08T10:02:54.813014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Résultat final ===\ntext_matrices = np.stack(text_matrices)  # shape: (nb_segments, 9, 300)\nprint(\"Shape finale des features textuels :\", text_matrices.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:02:54.813597Z","iopub.status.idle":"2025-05-08T10:02:54.813818Z","shell.execute_reply.started":"2025-05-08T10:02:54.813711Z","shell.execute_reply":"2025-05-08T10:02:54.813720Z"}},"outputs":[],"execution_count":null}]}