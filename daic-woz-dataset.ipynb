{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11699724,"sourceType":"datasetVersion","datasetId":7343598}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# üì• 1. Lire les fichiers CSV avec le bon s√©parateur\ntrain = pd.read_csv(\"/kaggle/input/daic-woz/train_split_Depression_AVEC2017 (2).csv\", sep=\",\")\ndev = pd.read_csv(\"/kaggle/input/daic-woz/dev_split_Depression_AVEC2017.csv\", sep=\",\")\ntest = pd.read_csv(\"/kaggle/input/daic-woz/full_test_split.csv\", sep=\",\")\n\n# üßΩ 2. Nettoyer les noms de colonnes\ntrain.columns = [col.strip() for col in train.columns]\ndev.columns = [col.strip() for col in dev.columns]\ntest.columns = [col.strip() for col in test.columns]\n\n# üîÅ 3. Renommer les colonnes pour harmoniser les noms\ntrain = train.rename(columns={\"PHQ8_Score\": \"PHQ_Score\", \"PHQ8_Binary\": \"PHQ_Binary\"})\ndev = dev.rename(columns={\"PHQ8_Score\": \"PHQ_Score\", \"PHQ8_Binary\": \"PHQ_Binary\"})\n\n# üìä 4. Garder seulement les colonnes n√©cessaires\ncolumns = ['Participant_ID', 'PHQ_Score', 'PHQ_Binary']\ntrain = train[columns]\ndev = dev[columns]\ntest = test[columns]\n\n# üìÇ 6. Ajouter les chemins des fichiers audio et des transcriptions\n# Suppose that audio and transcript files are stored in respective directories\naudio_dir = 'audio_files/'\ntranscript_dir = 'transcripts/'\n\n# Function to generate file paths based on Participant_ID\ndef get_file_paths(df, audio_dir, transcript_dir):\n    df['audio_path'] = df['Participant_ID'].apply(lambda x: os.path.join(audio_dir, f\"{x}_AUDIO.wav\"))\n    df['transcript_path'] = df['Participant_ID'].apply(lambda x: os.path.join(transcript_dir, f\"{x}_TRANSCRIPT.csv\"))\n    return df\n\ntrain = get_file_paths(train, audio_dir, transcript_dir)\ndev = get_file_paths(dev, audio_dir, transcript_dir)\ntest = get_file_paths(test, audio_dir, transcript_dir)\n\n# üß∑ 7. Concat√©ner les trois ensembles\nfull_df = pd.concat([train, dev, test], ignore_index=True)\n\n# ‚úÖ R√©sultat\nprint(full_df.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T18:50:36.006564Z","iopub.execute_input":"2025-05-17T18:50:36.006836Z","iopub.status.idle":"2025-05-17T18:50:38.316392Z","shell.execute_reply.started":"2025-05-17T18:50:36.006807Z","shell.execute_reply":"2025-05-17T18:50:38.315512Z"}},"outputs":[{"name":"stdout","text":"   Participant_ID  PHQ_Score  PHQ_Binary                 audio_path  \\\n0             303          0           0  audio_files/303_AUDIO.wav   \n1             304          6           0  audio_files/304_AUDIO.wav   \n2             305          7           0  audio_files/305_AUDIO.wav   \n3             310          4           0  audio_files/310_AUDIO.wav   \n4             312          2           0  audio_files/312_AUDIO.wav   \n\n                  transcript_path  \n0  transcripts/303_TRANSCRIPT.csv  \n1  transcripts/304_TRANSCRIPT.csv  \n2  transcripts/305_TRANSCRIPT.csv  \n3  transcripts/310_TRANSCRIPT.csv  \n4  transcripts/312_TRANSCRIPT.csv  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}