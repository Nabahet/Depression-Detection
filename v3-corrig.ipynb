{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11699724,"sourceType":"datasetVersion","datasetId":7343598}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install language-tool-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:13:16.784343Z","iopub.execute_input":"2025-05-08T11:13:16.784676Z","iopub.status.idle":"2025-05-08T11:13:19.698774Z","shell.execute_reply.started":"2025-05-08T11:13:16.784655Z","shell.execute_reply":"2025-05-08T11:13:19.697994Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (2.9.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (7.0.0)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.1.31)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nimport os\nimport re\nimport nltk\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport language_tool_python\nfrom gensim.models.fasttext import load_facebook_vectors\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-05-08T11:13:19.700627Z","iopub.execute_input":"2025-05-08T11:13:19.701310Z","iopub.status.idle":"2025-05-08T11:13:19.706536Z","shell.execute_reply.started":"2025-05-08T11:13:19.701286Z","shell.execute_reply":"2025-05-08T11:13:19.705714Z"},"trusted":true},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def load_audio(audio_path, sr=16000):\n    return librosa.load(audio_path, sr=sr)","metadata":{"execution":{"iopub.status.busy":"2025-05-08T11:13:19.707275Z","iopub.execute_input":"2025-05-08T11:13:19.707530Z","iopub.status.idle":"2025-05-08T11:13:19.721296Z","shell.execute_reply.started":"2025-05-08T11:13:19.707515Z","shell.execute_reply":"2025-05-08T11:13:19.720683Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def slice_patient_audio(y, sr, timestamps, segment_length=7.6):\n    \"\"\"Keep only patient’s speech using provided timestamps and split into 7.6s segments\"\"\"\n    patient_audio = np.concatenate([y[int(start*sr):int(end*sr)] for start, end in timestamps])\n    segments = []\n    segment_samples = int(segment_length * sr)\n    for i in range(0, len(patient_audio), segment_samples):\n        chunk = patient_audio[i:i + segment_samples]\n        if len(chunk) == segment_samples:\n            segments.append(chunk)\n    return segments\n","metadata":{"execution":{"iopub.status.busy":"2025-05-08T11:13:19.722202Z","iopub.execute_input":"2025-05-08T11:13:19.722445Z","iopub.status.idle":"2025-05-08T11:13:19.733889Z","shell.execute_reply.started":"2025-05-08T11:13:19.722429Z","shell.execute_reply":"2025-05-08T11:13:19.733142Z"},"trusted":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def add_noise(y, noise_factor):\n    return y + noise_factor * np.random.randn(len(y))","metadata":{"execution":{"iopub.status.busy":"2025-05-08T11:13:19.735781Z","iopub.execute_input":"2025-05-08T11:13:19.736011Z","iopub.status.idle":"2025-05-08T11:13:19.744118Z","shell.execute_reply.started":"2025-05-08T11:13:19.735997Z","shell.execute_reply":"2025-05-08T11:13:19.743514Z"},"trusted":true},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def pitch_shift(y, sr, steps):\n    return librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)","metadata":{"execution":{"iopub.status.busy":"2025-05-08T11:13:19.744920Z","iopub.execute_input":"2025-05-08T11:13:19.745403Z","iopub.status.idle":"2025-05-08T11:13:19.755894Z","shell.execute_reply.started":"2025-05-08T11:13:19.745382Z","shell.execute_reply":"2025-05-08T11:13:19.755355Z"},"trusted":true},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def extract_mfcc(y, sr=16000, n_mfcc=19, win_length=0.06):\n    hop_length = int(sr * win_length / 2)\n    win_len = int(sr * win_length)\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, \n                                hop_length=hop_length, win_length=win_len,\n                                window='hamming')\n    return mfcc.T  # shape (frames, n_mfcc)","metadata":{"execution":{"iopub.status.busy":"2025-05-08T11:13:19.756652Z","iopub.execute_input":"2025-05-08T11:13:19.756919Z","iopub.status.idle":"2025-05-08T11:13:19.767146Z","shell.execute_reply.started":"2025-05-08T11:13:19.756903Z","shell.execute_reply":"2025-05-08T11:13:19.766615Z"},"trusted":true},"outputs":[],"execution_count":42},{"cell_type":"code","source":"import torch.nn as nn\n# -------- CNN MODEL --------\n\nclass AudioCNNEncoder(nn.Module):\n    def __init__(self, input_shape):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1)\n        self.dropout = nn.Dropout(0.3)\n        self.flatten = nn.Flatten()\n        self.fc = nn.Linear(32 * input_shape[0] * input_shape[1], 128)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.flatten(x)\n        return self.fc(x)\n","metadata":{"execution":{"iopub.status.busy":"2025-05-08T11:13:19.767839Z","iopub.execute_input":"2025-05-08T11:13:19.768684Z","iopub.status.idle":"2025-05-08T11:13:19.779589Z","shell.execute_reply.started":"2025-05-08T11:13:19.768662Z","shell.execute_reply":"2025-05-08T11:13:19.778966Z"},"trusted":true},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def process_all_patients_audio(dataset_dir, cnn_model, sr=16000, segment_len=7.6, device='cpu'):\n    cnn_model.to(device)\n    cnn_model.eval()\n    \n\n    \n    participant_ids = [p for p in os.listdir(base_dir) if p.endswith('_P')]\n    processed_data = {}\n\n    for patient_id in participant_ids:\n        audio_path = os.path.join(base_dir, participant_id, f\"{participant_id.split('_')[0]}_AUDIO.wav\")\n        if not os.path.exists(audio_path): continue\n\n        y, _ = load_audio(audio_path, sr)\n        segments = slice_patient_audio(y, sr, patient_timestamps_dict[patient_prefix], segment_len)\n\n        embeddings = []\n\n        for seg in segments:\n            augmented_versions = [seg]\n            # Noise Injection\n            for alpha in [0.01, 0.02, 0.03]:\n                augmented_versions.append(add_noise(seg, alpha))\n            # Pitch Shifting\n            for steps in [-0.5, -2, -2.5]:\n                augmented_versions.append(pitch_shift(seg, sr, steps))\n\n            for aug in augmented_versions:\n                mfcc = extract_mfcc(aug, sr)  # shape: (frames, 19)\n                mfcc_tensor = torch.tensor(mfcc).unsqueeze(0).unsqueeze(0).float().to(device)  # (1, 1, frames, 19)\n                with torch.no_grad():\n                    embedding = cnn_model(mfcc_tensor)\n                embeddings.append(embedding.cpu().numpy())\n\n        # Average all embeddings for the patient\n        processed_data[patient_prefix] = np.mean(embeddings, axis=0)\n\n    return processed_data","metadata":{"execution":{"iopub.status.busy":"2025-05-08T11:13:19.780275Z","iopub.execute_input":"2025-05-08T11:13:19.780714Z","iopub.status.idle":"2025-05-08T11:13:19.793956Z","shell.execute_reply.started":"2025-05-08T11:13:19.780697Z","shell.execute_reply":"2025-05-08T11:13:19.793356Z"},"trusted":true},"outputs":[],"execution_count":44},{"cell_type":"code","source":"dummy = extract_mfcc(np.zeros(int(7.6*16000)), 16000)\ncnn_model = AudioCNNEncoder(input_shape=dummy.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:13:19.794678Z","iopub.execute_input":"2025-05-08T11:13:19.795433Z","iopub.status.idle":"2025-05-08T11:13:19.999903Z","shell.execute_reply.started":"2025-05-08T11:13:19.795416Z","shell.execute_reply":"2025-05-08T11:13:19.999251Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Téléchargement des ressources NLTK (à faire une seule fois dans un notebook Kaggle)\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:13:20.000705Z","iopub.execute_input":"2025-05-08T11:13:20.000968Z","iopub.status.idle":"2025-05-08T11:13:20.007136Z","shell.execute_reply.started":"2025-05-08T11:13:20.000947Z","shell.execute_reply":"2025-05-08T11:13:20.006529Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"# Préparation\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:13:20.008024Z","iopub.execute_input":"2025-05-08T11:13:20.008228Z","iopub.status.idle":"2025-05-08T11:13:20.019348Z","shell.execute_reply.started":"2025-05-08T11:13:20.008213Z","shell.execute_reply":"2025-05-08T11:13:20.018781Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Chargement du modèle GloVe léger\nprint(\"Chargement du modèle GloVe...\")\nmodel = api.load(\"glove-wiki-gigaword-50\")  # Vecteurs 50 dimensions\nprint(\"Modèle chargé.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:13:20.020004Z","iopub.execute_input":"2025-05-08T11:13:20.020247Z","iopub.status.idle":"2025-05-08T11:13:33.669341Z","shell.execute_reply.started":"2025-05-08T11:13:20.020232Z","shell.execute_reply":"2025-05-08T11:13:33.668511Z"}},"outputs":[{"name":"stdout","text":"Chargement du modèle GloVe...\nModèle chargé.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# Fonction de prétraitement du texte\ndef preprocess_text(text):\n    text = re.sub(r'[^\\w\\s]', '', text)  # Enlève la ponctuation\n    text = re.sub(r'\\d+', '', text)      # Enlève les chiffres\n    text = text.lower().strip()          # Minuscule + trim\n    tokens = word_tokenize(text)\n    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    return tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:13:33.671728Z","iopub.execute_input":"2025-05-08T11:13:33.671957Z","iopub.status.idle":"2025-05-08T11:13:33.676409Z","shell.execute_reply.started":"2025-05-08T11:13:33.671940Z","shell.execute_reply":"2025-05-08T11:13:33.675663Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Fonction pour convertir une phrase en matrice de vecteurs\ndef text_to_embedding_matrix(text, vector_size=50, max_len=9):\n    tokens = preprocess_text(text)\n    matrix = []\n    \n    for word in tokens[:max_len]:\n        if word in model:\n            matrix.append(model[word])\n        else:\n            matrix.append(np.zeros(vector_size))  # Si mot inconnu, vecteur nul\n            \n    # Padding si moins de `max_len` mots\n    while len(matrix) < max_len:\n        matrix.append(np.zeros(vector_size))\n    \n    return np.array(matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:13:33.677074Z","iopub.execute_input":"2025-05-08T11:13:33.677269Z","iopub.status.idle":"2025-05-08T11:13:33.689087Z","shell.execute_reply.started":"2025-05-08T11:13:33.677255Z","shell.execute_reply":"2025-05-08T11:13:33.688493Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\nembedding_model = api.load(\"glove-wiki-gigaword-50\")\nvector_size = 50\n\ndef preprocess_text(text, max_len=9):\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\d+', '', text)\n    text = text.lower().strip()\n    tokens = word_tokenize(text)\n    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    \n    vectors = []\n    for word in tokens[:max_len]:\n        if word in embedding_model:\n            vectors.append(embedding_model[word])\n        else:\n            vectors.append(np.zeros(vector_size))\n    while len(vectors) < max_len:\n        vectors.append(np.zeros(vector_size))\n    return np.array(vectors)\n\ndef extract_audio_features(audio_path, start, end, sr=16000):\n    audio, _ = librosa.load(audio_path, sr=sr)\n    start_sample = int(start * sr)\n    end_sample = int(end * sr)\n    segment = audio[start_sample:end_sample]\n    \n    # MFCCs shape = (n_mfcc, time_frames)\n    mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)\n    # Flatten to fixed size vector\n    return np.mean(mfcc, axis=1)  # (13,) moyen par MFCC\n\ndef preprocess_daic_sample(folder_path, window_size=7.6):\n    transcript_path = os.path.join(folder_path, [f for f in os.listdir(folder_path) if f.endswith('_TRANSCRIPT.csv')][0])\n    audio_path = os.path.join(folder_path, [f for f in os.listdir(folder_path) if f.endswith('_AUDIO.wav')][0])\n    \n    df = pd.read_csv(transcript_path, sep='\\t')\n    df = df.dropna(subset=[\"value\"])\n    \n    samples = []\n    \n    for i in range(len(df)):\n        row = df.iloc[i]\n        if row['speaker'].lower() == \"participant\":\n            start = row['start_time']\n            end = min(start + window_size, row['stop_time'])\n            sentence = row['value']\n            \n            # Texte prétraité en embedding\n            text_embed = preprocess_text(sentence)  # shape (9, 50)\n            \n            # Audio MFCC\n            mfcc_feat = extract_audio_features(audio_path, start, end)  # shape (13,)\n            \n            # Texte de l'intervieweur juste avant\n            prev_text = \"\"\n            if i > 0 and df.iloc[i-1]['speaker'].lower() != \"participant\":\n                prev_text = df.iloc[i-1]['value']\n            context_embed = preprocess_text(prev_text)\n            \n            # On stocke tout\n            samples.append({\n                \"text_embedding\": text_embed,\n                \"context_embedding\": context_embed,\n                \"mfcc\": mfcc_feat,\n                \"start\": start,\n                \"end\": end,\n                \"text\": sentence,\n                \"context\": prev_text\n            })\n    \n    return samples\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:19:08.571115Z","iopub.execute_input":"2025-05-08T11:19:08.571486Z","iopub.status.idle":"2025-05-08T11:19:22.271129Z","shell.execute_reply.started":"2025-05-08T11:19:08.571465Z","shell.execute_reply":"2025-05-08T11:19:22.270625Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}